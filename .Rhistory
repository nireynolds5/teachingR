p_grid <- seq(from=0 , to=1 , length.out=grid_size)
transparency_of_points <- 15/grid_size + 0.05
y_max <- 1.1 * max(posterior, posterior_with_error)
# (3) Now we plot posterior with both models
plot(p_grid, posterior_with_error
, pch = 19
, type = "b"
, lwd = 2
, col = alpha("slateblue1", transparency_of_points)
, xlab="probability of water"
, ylab="posterior probability"
, ylim=c(0, y_max)
#, yaxt='n'
)
points(p_grid, posterior
, pch = 19
, col = alpha("red", transparency_of_points)
, type = "b"
, lwd = 2
)
prior <- rep(1, grid_size)
prior <- prior/sum(prior)
Z <- L+W
likelihood <- ((((p_grid*(1-error_rate_fn)) + ((1-p_grid)*error_rate_fn))^W) * ((((1-p_grid)*(1-error_rate_fn)) + (p_grid*error_rate_fn))^L) )/ Z
points(p_grid, prior
, pch = 19, col = "purple4"
, type = 'l'
, lwd = 3)
points(p_grid, likelihood * 0.02/max(likelihood)
, pch = 19, col = "darkseagreen"
, type = 'l'
, lwd = 3)
# As expected, since the prior is flat, the likelihood is very similar to the posterior
# with error (which is the likelihood I used). Also note that I rescaled the likelihood so
# its pattern would be visible.
w <- 6; n <- 9;
p_grid <- seq(from=0,to=1,length.out=100)
posterior <- dbinom(w,n,p_grid)*dunif(p_grid,0,1)
posterior <- posterior/sum(posterior)
plot(posterior)
MyDatafromGoogleSheets <-
MyDatafromGithub <- read.csv("https://raw.githubusercontent.com/shannonmcwaters/Directed-exploration/refs/heads/main/Maze%20Data%20Raw")
setwd("C:/Users/dornh/Dropbox/Github/teachingR")
# But note that this is a little problematic as this detailed path
# would never work on someone else's computer. Instead,
# you can also use
setwd("../teachingR")
# But note that this is a little problematic as this detailed path
# would never work on someone else's computer. Instead,
# you can also use
setwd("/teachingR")
# But note that this is a little problematic as this detailed path
# would never work on someone else's computer. Instead,
# you can also use
setwd("../teachingR")
# Or directly from a Google Sheet:
MyDatafromGoogleSheets <- read_csv("https://docs.google.com/spreadsheets/d/1K2D2rH770iDfZzlwakHK89bwvoPqWDLaHbVNsanJFX8/gviz/tq?tqx=out:csv")
# Or directly from a Google Sheet:
MyDatafromGoogleSheets <- read.csv("https://docs.google.com/spreadsheets/d/1K2D2rH770iDfZzlwakHK89bwvoPqWDLaHbVNsanJFX8/gviz/tq?tqx=out:csv")
library(rstan)
#install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
## Then install 'rethinking' package for the book-specific functions.
# From 2019 book:
#install.packages(c("coda","mvtnorm","devtools"))
library(devtools)
#devtools::install_github("rmcelreath/rethinking",ref="Experimental")
#devtools::install_github("rmcelreath/rethinking", force=TRUE)
# From R Documentation:
#devtools::install_github("stan-dev/cmdstanr")
#install.packages(c("coda","mvtnorm","devtools","loo","dagitty"))
#devtools::install_github("rmcelreath/rethinking")
## LIBRARIES  -----------------------------
# Do I need these? I don't think so
#library(cmdstanr)
#library(posterior)
#library(bayesplot)
#color_scheme_set("brightblue")
library(rethinking)
library(scales)
no_of_samples <- 9
no_of_successes <- 6
# Here this is the probability density for a binomial function
# which is what you need when drawing with replacement
dbinom(no_of_successes, size=no_of_samples , prob=0.5 )
# Here this is the probability density for a binomial function
# which is what you need when drawing with replacement
pbinom(no_of_successes, size=no_of_samples, prob=0.5)
# Here this is the probability density for a binomial function
# which is what you need when drawing with replacement
dbinom(no_of_successes, size=no_of_samples, prob=0.5)
# Here this is the probability density for a binomial function
# which is what you need when drawing with replacement
dbinom(2, size=no_of_samples, prob=0.5)
# Here this is the probability density for a binomial function
# which is what you need when drawing with replacement
dbinom(0, size=no_of_samples, prob=0.5)
library(rethinking)
library(scales)  # for number_format & color scales
library(viridis)
# Graphics setup -----------------------------
no_categories <- 6
## Colorpalette
twogroupcolors <- c("#5a9a8f", "#7b6ea8")
threegroupcolors <- viridis(3)
severalcategories_colors <- magma(no_categories)
## Similar to colors, it often makes sense to define some other things
## universally for all your plots, e.g. margins, where the sample sizes
## are plotted, y-axis range. This depends on your figures though.
y_max <- 6
y_min <- 0
N_y_offset <- 0.95 # This puts sample size numbers 5% below max, for example
# IMPORT ----------------------------------
# A common problem when reading any files is that you must make sure
# that R uses the folder you want as 'working directory'. You can
# pick the working directory from the 'Session' menu above; or
# you can write the path here in the code, e.g.:
setwd("C:/Users/dornh/Dropbox/Github/teachingR")
# But note that this is a little problematic as this detailed path
# would never work on someone else's computer. Instead,
# you can also use
setwd("../teachingR")
# or similar ... the ".." means 'go up one directory level' and then
# it will go into the folder to the right of the "/".
MyData <- read.table("bb col data.csv"
, header=T
, row.names=1
, sep = ","
, dec = "."
)
# Or you can load a .csv file from Google Drive:
path <- "C:/Users/dornh/Dropbox/TEACHING/ECOL496G 596G Spring2025 Networks/network datasets/Memmott pollinator network/"
MyDatafromGoogleDrive <- read.table(paste(path, "memmott_1999.csv", sep = ""), header = TRUE, sep = ",")
# Or directly from a Google Sheet:
MyDatafromGoogleSheets <- read.csv("https://docs.google.com/spreadsheets/d/1K2D2rH770iDfZzlwakHK89bwvoPqWDLaHbVNsanJFX8/gviz/tq?tqx=out:csv")
# Or directly from github:
MyDatafromGithub <- read.csv("https://raw.githubusercontent.com/shannonmcwaters/Directed-exploration/refs/heads/main/Maze%20Data%20Raw")
View(MyDatafromGoogleDrive)
View(MyDatafromGoogleSheets)
# Bare boxplot
boxplot(avgsize ~ treatment
, data = MyData
, xlab = "X Concept [unit measured]"
, ylab = "Y Concept [unit measured]"
, col = threegroupcolors
, range = 0
)
# GRAPHING THINGS ------------------------------
# Bare boxplot
boxplot(avgsize ~ treatment
, data = MyData
, xlab = "X Concept [unit measured]"
, ylab = "Y Concept [unit measured]"
, col = threegroupcolors
, range = 0
)
# Fancy boxplot - but this should be your default
# What makes it fancy:
# Adjust margins
# Add sample sizes
# Add data points
# Margins:
par(oma = c(2,2,2,2), mar = c(4,4,1,1), mgp=c(3, 1, 0), las=1)
# bottom, left, top, right
par(mfrow=c(1,1))
# How to make a great boxplot -
# Saving the plot into a variable allows us to access plot parameters afterwards.
Nice_Plot <- boxplot(avgsize ~ treatment
, data = MyData
, xlab = "X Concept [unit measured]"
, ylab = "Y Concept [unit measured]"
, range = 0
# Always make axis descriptions as clear and comprehensive as possible
, names = c("Large bees", "Middling bees", "Small bees")
, col = alpha(threegroupcolors, 0.5) # use same colors as elsewhere,
# but slightly transparent so we can see data points
, ylim = c(y_min, y_max) # always think about the scale - starting from zero is typically better
)
# Putting sample sizes above bars
nbGroup <- nlevels(as.factor(Nice_Plot$names)) # this is just a way to extract
# category names from the plot - you could get this directly from data
text(x=c(1:nbGroup)
, y=N_y_offset*y_max
, cex = 1
, col = threegroupcolors
, paste("N=", Nice_Plot$n, sep="")  # again, the sample size 'n' is directly extracted from the plot
)
mtext("additional margin label", side=2, line=2, las=0)
mtext("additional margin label on outside", side=1, line=5, las=0, xpd = TRUE)
# Represent the raw data as well, especially for mid- to low sample sizes.
stripchart(avgsize ~ treatment
, data = MyData
, add = TRUE # this plots this graph on top of the existing one
, pch = 19
, col = threegroupcolors
, method = "jitter"
, jitter = 0.2
, vertical = TRUE
)
View(MyDatafromGoogleDrive)
View(MyData)
graph_data <- MyData
# We can even upgrade this to a multi-panel plot. For this we can use another par()
# setting (e.g. mfrow=c(2,2)), or for more control use 'layout()'.
layout(matrix(c(1,2,0,3), 2, 2, byrow = T), widths=c(1,5),
heights=c(5,1))
# This gives us a four-panel plot; the plots will be inserted into the panels in
# order by row.
# Various other format adjustments
par(oma = c(0,0,0,0), mgp=c(3, 1, 0), las=1)
# Panel 1:
par(mar = c(4,0,1,0)) # bottom, left, top, right
boxplot(table(avgsize)
, data = graph_data
, xaxt = 'n'
, yaxt = 'n'
, frame = FALSE
, range = 0
, col = color_distributions
)
boxplot(table(graph_data$avgsize)
, data = graph_data
, xaxt = 'n'
, yaxt = 'n'
, frame = FALSE
, range = 0
, col = color_distributions
)
boxplot(table(graph_data$avgsize)
, data = graph_data
, xaxt = 'n'
, yaxt = 'n'
, frame = FALSE
, range = 0
#        , col = color_distributions
)
table(graph_data$avgsize)
# But note that this is a little problematic as this detailed path
# would never work on someone else's computer. Instead,
# you can also use
setwd("../teachingR/example_data")
# But note that this is a little problematic as this detailed path
# would never work on someone else's computer. Instead,
# you can also use
setwd("../teachingR")
# A common problem when reading any files is that you must make sure
# that R uses the folder you want as 'working directory'. You can
# pick the working directory from the 'Session' menu above; or
# you can write the path here in the code, e.g.:
setwd("C:/Users/dornh/Dropbox/Github/teachingR")
# Import a whole list of files,
# specifically all csv files from folder '
files <- (Sys.glob("example_data/*.csv"))
files <- (Sys.glob("example_data/*.csv"))
# Initiate a blank data frame
EnormousData <- data.frame()
# Read content of all files into a list
listOfDataframes <- lapply(files,
function(x) {
read.table(x,
header = T,
sep = ",",
skip = 6
)
}
)
# Add all the rows from all the files together
EnormousData <- do.call("bind_rows", listOfDataframes)
# Or you can load a .csv file from Google Drive:
path <- "https://drive.google.com/drive/folders/1aZWvhJjgTH9QTrD9hV1LiPiOKFRxmH7x/"
MyDatafromGoogleDrive <- read.table(paste(path, "memmott_1999.csv", sep = ""), header = TRUE, sep = ",")
path <- "https://drive.google.com/drive/folders/1aZWvhJjgTH9QTrD9hV1LiPiOKFRxmH7x/"
files <- (Sys.glob(paste(path, "*.xlsx")))
EnormousData <- data.frame()
# Read content of all files into a list
listOfDataframes <- lapply(files,
function(x) {
read.table(x,
header = T,
sep = ",",
)
}
)
# Add all the rows from all the files together
EnormousData <- do.call("bind_rows", listOfDataframes)
library(tidyverse)
# Add all the rows from all the files together
EnormousData <- do.call("bind_rows", listOfDataframes)
# Or for local files:
path <- "/example_data/similardatasheets"
files <- (Sys.glob(paste(path, "*.csv")))
# Or for local files:
path <- "/example_data/similardatasheets/"
pathwild <- paste(path, "*.csv")
files <- (Sys.glob(pathwild))
files <- (Sys.glob("/example_data/similardatasheets/*.csv"))
files <- (Sys.glob("./example_data/similardatasheets/*.csv"))
files
path <- "./example_data/similardatasheets/"
pathwild <- paste(path, "*.csv")
files <- (Sys.glob(pathwild))
EnormousData <- data.frame()
# Read content of all files into a list
listOfDataframes <- lapply(files,
function(x) {
read.table(x,
header = T,
sep = ",",
skip = 6
)
}
)
# Add all the rows from all the files together
EnormousData <- do.call("bind_rows", listOfDataframes)
read.table(files[[1]])
str(files)
# Or for local files:
files <- (Sys.glob("./example_data/similardatasheets/*.csv"))
EnormousData <- data.frame()
# Read content of all files into a list
listOfDataframes <- lapply(files,
function(x) {
read.table(x,
header = T,
sep = ",",
skip = 6
)
}
)
# Add all the rows from all the files together
EnormousData <- do.call("bind_rows", listOfDataframes)
#
install.packages("googledrive")
library(googledrive)
drive_ls(path = "https://drive.google.com/drive/folders/1aZWvhJjgTH9QTrD9hV1LiPiOKFRxmH7x/")
drive_ls(path = "https://drive.google.com/drive/folders/1xIhjFMzv9D3p2s88lG-5wHzu_aXjmLWx")
library(googledrive)
drive_ls(path = "https://drive.google.com/drive/folders/1xIhjFMzv9D3p2s88lG-5wHzu_aXjmLWx")
install.packages("readxl")
library(readxl)
library(tidyverse) # for bind.rows
# File access
library(googledrive)
library(readxl)
# Colors
library(scales)  # for number_format & color scales
library(viridis)
drive_ls(path = "~/")
# File access
library(googledrive)
drive_ls(path = "~/")
library(tidyverse) # for bind.rows
# File access
library(googledrive)
library(readxl)
# Colors
library(scales)  # for number_format & color scales
library(viridis)
# Making output tables for statistical models
library(sjPlot) # for linear models output tables
drive_list()
# File access
library(googledrive)
drive_list()
installed.packages()
detach("package:ggplot2", unload = TRUE)
library(ggplot2)
drive_ls()
drive_ls()
# General data handling
library(tidyverse) # for bind.rows
# File access
library(googledrive)
library(readxl)
# Colors
library(scales)  # for number_format & color scales
library(viridis)
# Making output tables for statistical models
library(sjPlot) # for linear models output tables
drive_ls()
MyDatafromGoogleDrive  <- drive_download(
as_id("https://drive.google.com/drive/folders/1aZWvhJjgTH9QTrD9hV1LiPiOKFRxmH7x"),
path = 'V10112_beh.xlsx',
overwrite = TRUE,
type = "xlsx")
MyDatafromGoogleDrive  <- drive_download(
as_id("https://docs.google.com/spreadsheets/d/1sF5WnJs0uxeLKApn7_JzGJMozu6wgSPJ/edit"),
path = 'V10112_beh.xlsx',
overwrite = TRUE,
type = "xlsx")
MyDatafromGoogleDrive  <- read_excel(drive_read_raw(
as_id("https://docs.google.com/spreadsheets/d/1sF5WnJs0uxeLKApn7_JzGJMozu6wgSPJ/edit"),
path = 'V10112_beh.xlsx',
type = "xlsx"))
MyDatafromGoogleDrive  <- read_excel(
drive_read_raw(
as_id("https://docs.google.com/spreadsheets/d/1sF5WnJs0uxeLKApn7_JzGJMozu6wgSPJ/edit")
)
)
temp <-   drive_read_raw(
as_id("https://docs.google.com/spreadsheets/d/1sF5WnJs0uxeLKApn7_JzGJMozu6wgSPJ/edit")
)
str(temp)
temp <-   drive_read_string(
as_id("https://docs.google.com/spreadsheets/d/1sF5WnJs0uxeLKApn7_JzGJMozu6wgSPJ/edit")
)
str(temp)
temp <-   drive_read_raw(
as_id("https://docs.google.com/spreadsheets/d/1sF5WnJs0uxeLKApn7_JzGJMozu6wgSPJ/edit")
)
install.packages("googlesheets4")
install.packages("googlesheets4")
library(googlesheets4)
sprintf()
?sprintf
# Or you can load a .csv or .xlsx file from Google Drive:
# (example is an xlsx file)
MyDatafromGoogleDrive  <- read_excel("https://docs.google.com/spreadsheets/d/1sF5WnJs0uxeLKApn7_JzGJMozu6wgSPJ/edit?gid=245566794#gid=245566794")
# Or you can load a .csv or .xlsx file from Google Drive:
# (example is an xlsx file)
MyDatafromGoogleDrive  <- read_sheet("https://docs.google.com/spreadsheets/d/1sF5WnJs0uxeLKApn7_JzGJMozu6wgSPJ/edit?gid=245566794#gid=245566794")
library(readxl)
library(googlesheets4)
MyDatafromGoogleDrive  <- read_sheet(
"https://docs.google.com/spreadsheets/d/1sF5WnJs0uxeLKApn7_JzGJMozu6wgSPJ/edit#gid=245566794"
)
MyDatafromGoogleDrive  <- read_sheet(
"https://docs.google.com/spreadsheets/d/1sF5WnJs0uxeLKApn7_JzGJMozu6wgSPJ/edit#gid=245566794"
)
gs4_get(  "https://docs.google.com/spreadsheets/d/1sF5WnJs0uxeLKApn7_JzGJMozu6wgSPJ/edit#gid=245566794"
)
gs4_get(  "https://drive.google.com/file/d/1woJYnpsfMBPCC3kPSErcydgDCduEKjzy/edit"
)
gs4_get(  "https://drive.google.com/file/d/1woJYnpsfMBPCC3kPSErcydgDCduEKjzy/"
)
gs4_get(  "https://drive.google.com/file/d/1woJYnpsfMBPCC3kPSErcydgDCduEKjzy"
)
gs4_get("https://drive.google.com/file/d/1woJYnpsfMBPCC3kPSErcydgDCduEKjzy"
)
MyDatafromGoogleDrive  <- read_sheet(
"https://drive.google.com/file/d/1woJYnpsfMBPCC3kPSErcydgDCduEKjzy/edit#gid="
)
MyDatafromGoogleDrive  <- read_sheet(
"https://drive.google.com/file/d/1woJYnpsfMBPCC3kPSErcydgDCduEKjzy/edit#gid"
)
MyDatafromGoogleDrive  <- read_sheet(
"https://drive.google.com/file/d/1woJYnpsfMBPCC3kPSErcydgDCduEKjzy/gviz/tq?tqx=out:csv"
)
test <- read_excel("https://drive.google.com/uc?export=download&id=1sF5WnJs0uxeLKApn7_JzGJMozu6wgSPJ")
# Or
MyDatafromGoogleSheets <- read.csv("https://drive.google.com/uc?export=download&id=1sF5WnJs0uxeLKApn7_JzGJMozu6wgSPJ")
View(MyDatafromGoogleSheets)
# Or
MyDatafromGoogleSheets <- read.csv("https://drive.google.com/uc?export=download&id=1woJYnpsfMBPCC3kPSErcydgDCduEKjzy")
# An .xlsx file from Google Drive is more complicated:
# You have to first download the file into a local file, then
# import the local file into R.
googlepath <- "https://docs.google.com/spreadsheets/d/1sF5WnJs0uxeLKApn7_JzGJMozu6wgSPJ/edit"
drive_download(googlepath, path = tempxlsfile, overwrite = TRUE)
tempxlsfile <- tempfile(fileext = ".xlsx")
# An .xlsx file from Google Drive is more complicated:
# You have to first download the file into a local file, then
# import the local file into R.
googlepath <- "https://docs.google.com/spreadsheets/d/1sF5WnJs0uxeLKApn7_JzGJMozu6wgSPJ/edit"
drive_download(as.id(googlepath), path = tempxlsfile, overwrite = TRUE)
drive_download(as_id(googlepath), path = tempxlsfile, overwrite = TRUE)
MyDatafromGoogleDrive  <- read_excel(tempxlsfile)
View(MyDatafromGoogleDrive)
unlink(tempxlsfile)
drive_ls()
# Import a whole list of xls files
# Headache! Saving as csv is better...
drive_ls(as_id("https://drive.google.com/drive/folders/1aZWvhJjgTH9QTrD9hV1LiPiOKFRxmH7x"))
# Import a whole list of files
# Note that this will only work if all the files have the same columns (and otherwise
# it is anyway doubtful that this would make sense)
files <- (Sys.glob("./example_data/similardatasheets/*.csv"))
str(files)
# Import a whole list of xls files
# Headache! Saving as csv is better...
googledrivefolderfiles <- drive_ls(as_id("https://drive.google.com/drive/folders/1aZWvhJjgTH9QTrD9hV1LiPiOKFRxmH7x"))
googledrivefolderfiles$name
files2 <- googledrivefolderfiles$id
files_local <- vector(mode = "chr", length = length(files2))
files_local <- vector(length = length(files2))
files_local <- vector(mode = "character", length = length(files2))
googledrivefolderfiles <- drive_ls(as_id("https://drive.google.com/drive/folders/1aZWvhJjgTH9QTrD9hV1LiPiOKFRxmH7x"))
files2 <- googledrivefolderfiles$id
names2 <- googledrivefolderfiles$name
files_local <- vector(mode = "character", length = length(files2))
for (i in 1:length(files2)) {
# Put name in files_local
files_local[i] <- paste("./temp/", names2[i])
# Download file
drive_download(files2[i], path = files_local[i], overwrite = TRUE)
}
dir.create(file.path("./", "temp"), showWarnings = FALSE)
for (i in 1:length(files2)) {
# Put name in files_local
files_local[i] <- paste("./temp/", names2[i])
# Download file
drive_download(files2[i], path = files_local[i], overwrite = TRUE)
}
EnormousData <- data.frame()
# Read content of all files into a list
listOfDataframes <- lapply(files_local,
function(x) {
read_excel(x)
}
)
# Add all the rows from all the files together
EnormousData <- do.call("bind_rows", listOfDataframes)
View(EnormousData)
